{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_Xfi0cFON-_"
      },
      "source": [
        "The objetive of this project is to identify a person from the way they type on keyboard. The time intervals pattern between keystrockes could constitute a \"finguerprint\" that is characteristic to an indivitual person. I will be testing here is this concept on two indivuals, trying to predic who is typing.\r\n",
        "I first collected the raw data using a keylogger python code, this provided me with the two files: keylog1.txt and keylog2.tex, each belong to a typer. I will be using the keras library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzsiggwGKx6n"
      },
      "source": [
        "import keras\r\n",
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5Et1wvRRvuA"
      },
      "source": [
        "We need first to clean the data. each line of the files is composed a date, a time and a character, for example: \" 2021-03-07 22:38:02,689: 'h' \" is the line generated by typing 'h'. The goal of the cleaning code, is to generate a list of four letters words, each two consequetive letters are seperated by their time intervals. So our training data will be a list of 7 elements arrays. a letter will be represented by a number which is its alphabetic order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Ur2DvGWlwt"
      },
      "source": [
        "f = open(\"keyLog1.txt\", encoding=\"utf8\", errors='ignore')\r\n",
        "Training1 = []\r\n",
        "e = 0\r\n",
        "N = np.zeros(7)\r\n",
        "for x in f:\r\n",
        "    if len(x[20:]) > 9:\r\n",
        "        e = 0\r\n",
        "        N = np.zeros(8)\r\n",
        "    elif (len(x[20:]) == 9) and ( 96 < ord(x[26:27]) < 123 ):\r\n",
        "        if (e == 0):\r\n",
        "            I = int(x[20:23])\r\n",
        "        if (e < 4):\r\n",
        "            e = e + 1\r\n",
        "        if (e == 1):\r\n",
        "            N[0] = ord(x[26:27]) - 96\r\n",
        "        if(5>e>1):\r\n",
        "            N[2*e-2]= ord(x[26:27]) - 96\r\n",
        "            N[2*e-3]= int(x[20:23]) - I + 999*bool(int(x[20:23]) < I)\r\n",
        "            I = int(x[20:23])\r\n",
        "        if(e == 4):\r\n",
        "            Training1.append(list(N))\r\n",
        "            e = 5"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL0-qh74deHd",
        "outputId": "90859868-8bdc-49fe-c095-3d01129d0ef2"
      },
      "source": [
        "np.shape(Training1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(373, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dQYU3-vWA_a"
      },
      "source": [
        "The cleaning code for the second file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z_nIdZQ0zUW"
      },
      "source": [
        "f = open(\"keyLog2.txt\", encoding=\"utf8\", errors='ignore')\r\n",
        "Training2 = []\r\n",
        "e = 0\r\n",
        "N = np.zeros(7)\r\n",
        "for x in f:\r\n",
        "    if len(x[20:]) > 9:\r\n",
        "        e = 0\r\n",
        "        N = np.zeros(8)\r\n",
        "    elif (len(x[20:]) == 9) and ( 96 < ord(x[26:27]) < 123 ):\r\n",
        "        if (e == 0):\r\n",
        "            I = int(x[20:23])\r\n",
        "        if (e < 4):\r\n",
        "            e = e + 1\r\n",
        "        if (e == 1):\r\n",
        "            N[0] = ord(x[26:27]) - 96\r\n",
        "        if(5>e>1):\r\n",
        "            N[2*e-2]= ord(x[26:27]) - 96\r\n",
        "            N[2*e-3]= int(x[20:23]) - I + 999*bool(int(x[20:23]) < I)\r\n",
        "            I = int(x[20:23])\r\n",
        "        if(e == 4):\r\n",
        "            Training2.append(list(N))\r\n",
        "            e = 5"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQjuJbzu09bI",
        "outputId": "a6f1f923-82a5-44ce-ef68-3332814017f6"
      },
      "source": [
        "np.shape(Training2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(422, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49aygm_WWIm4"
      },
      "source": [
        "Now we combine the two list of data and then we create as labels list.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NbHjflw1FWq",
        "outputId": "7afc479d-04db-42a5-de6c-48df43238152"
      },
      "source": [
        "Training = list(Training1)+list(Training2) # Combining the two lists\r\n",
        "Labels = list(np.ones(len(Training1))) + list(np.zeros(len(Training2)))\r\n",
        "print(np.shape(Training))\r\n",
        "print(np.shape(Labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(795, 8)\n",
            "(795,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtdaMtNvWhvL"
      },
      "source": [
        "Now we shuffle the data list and lable list in the same way. then we choose 10% of each list to serve as test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JioAyMTB2uYR",
        "outputId": "10f97882-f7ce-4538-c9b6-360807232a36"
      },
      "source": [
        "p = np.random.permutation(len(Training))\r\n",
        "train_data = [Training[p[x]] for x in range(len(Training))][:int(0.9*len(Training))]\r\n",
        "train_labels = [Labels[p[x]] for x in range(len(Training))][:int(0.9*len(Training))]\r\n",
        "test_data = [Training[p[x]] for x in range(len(Training))][int(0.9*len(Training)):]\r\n",
        "test_labels = [Labels[p[x]] for x in range(len(Training))][int(0.9*len(Training)):]\r\n",
        "print(np.shape(train_data))\r\n",
        "print(np.shape(train_labels))\r\n",
        "print(np.shape(test_data))\r\n",
        "print(np.shape(test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(715, 8)\n",
            "(715,)\n",
            "(80, 8)\n",
            "(80,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI1b1FwU7XHQ"
      },
      "source": [
        "from keras import models \r\n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvI8_PgcXAoY"
      },
      "source": [
        "We choose the parameters that are adapted to our problem:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0e8ZTwE7Yk-"
      },
      "source": [
        "model = models.Sequential() \r\n",
        "model.add(layers.Dense(70, activation='relu', input_shape=(8,))) \r\n",
        "model.add(layers.Dense(2, activation='sigmoid'))\r\n",
        "model.compile(optimizer='adam', \r\n",
        "    loss='binary_crossentropy', \r\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wavWZHnx7v8J"
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pI9Qcg47w6z"
      },
      "source": [
        "train_labels = to_categorical(train_labels) \r\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42yms5VKAcga",
        "outputId": "5c676aa8-41e7-44f4-8289-02ed83d6f6c8"
      },
      "source": [
        "np.shape(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(715, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPROMDd18Cjl",
        "outputId": "f3e6aa6b-d3a1-49ae-864f-1f1fa2f7c830"
      },
      "source": [
        "history=model.fit(np.array(train_data), np.array(train_labels), epochs=150, batch_size=715)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 26.0827 - accuracy: 0.5357\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 24.3193 - accuracy: 0.5371\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.5732 - accuracy: 0.5371\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 20.8739 - accuracy: 0.5357\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 19.2688 - accuracy: 0.5315\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.7866 - accuracy: 0.5301\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.4308 - accuracy: 0.5287\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 15.1442 - accuracy: 0.5273\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.8838 - accuracy: 0.5273\n",
            "Epoch 10/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.6231 - accuracy: 0.5329\n",
            "Epoch 11/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.3578 - accuracy: 0.5287\n",
            "Epoch 12/150\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.0771 - accuracy: 0.5315\n",
            "Epoch 13/150\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.7934 - accuracy: 0.5259\n",
            "Epoch 14/150\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.5314 - accuracy: 0.5287\n",
            "Epoch 15/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3492 - accuracy: 0.5273\n",
            "Epoch 16/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3090 - accuracy: 0.5357\n",
            "Epoch 17/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4600 - accuracy: 0.5427\n",
            "Epoch 18/150\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8063 - accuracy: 0.5259\n",
            "Epoch 19/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3946 - accuracy: 0.5315\n",
            "Epoch 20/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2689 - accuracy: 0.5357\n",
            "Epoch 21/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3688 - accuracy: 0.5524\n",
            "Epoch 22/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6043 - accuracy: 0.5329\n",
            "Epoch 23/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8341 - accuracy: 0.5287\n",
            "Epoch 24/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9983 - accuracy: 0.5245\n",
            "Epoch 25/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0849 - accuracy: 0.5147\n",
            "Epoch 26/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0982 - accuracy: 0.5133\n",
            "Epoch 27/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0525 - accuracy: 0.5203\n",
            "Epoch 28/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9632 - accuracy: 0.5329\n",
            "Epoch 29/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8370 - accuracy: 0.5371\n",
            "Epoch 30/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6744 - accuracy: 0.5483\n",
            "Epoch 31/150\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4742 - accuracy: 0.5524\n",
            "Epoch 32/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2420 - accuracy: 0.5706\n",
            "Epoch 33/150\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.9900 - accuracy: 0.5664\n",
            "Epoch 34/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7370 - accuracy: 0.5664\n",
            "Epoch 35/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5092 - accuracy: 0.5734\n",
            "Epoch 36/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3277 - accuracy: 0.5776\n",
            "Epoch 37/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2153 - accuracy: 0.5860\n",
            "Epoch 38/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1799 - accuracy: 0.5790\n",
            "Epoch 39/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.5734\n",
            "Epoch 40/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2322 - accuracy: 0.5832\n",
            "Epoch 41/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2570 - accuracy: 0.5776\n",
            "Epoch 42/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2537 - accuracy: 0.5804\n",
            "Epoch 43/150\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2154 - accuracy: 0.5818\n",
            "Epoch 44/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1435 - accuracy: 0.5818\n",
            "Epoch 45/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0466 - accuracy: 0.5832\n",
            "Epoch 46/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9384 - accuracy: 0.5958\n",
            "Epoch 47/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8350 - accuracy: 0.6028\n",
            "Epoch 48/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7523 - accuracy: 0.5972\n",
            "Epoch 49/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6975 - accuracy: 0.6084\n",
            "Epoch 50/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6683 - accuracy: 0.6070\n",
            "Epoch 51/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6558 - accuracy: 0.6210\n",
            "Epoch 52/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6501 - accuracy: 0.6224\n",
            "Epoch 53/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6426 - accuracy: 0.6224\n",
            "Epoch 54/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6272 - accuracy: 0.6252\n",
            "Epoch 55/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6011 - accuracy: 0.6336\n",
            "Epoch 56/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5648 - accuracy: 0.6322\n",
            "Epoch 57/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5216 - accuracy: 0.6308\n",
            "Epoch 58/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4758 - accuracy: 0.6308\n",
            "Epoch 59/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4336 - accuracy: 0.6322\n",
            "Epoch 60/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3998 - accuracy: 0.6406\n",
            "Epoch 61/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3774 - accuracy: 0.6378\n",
            "Epoch 62/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3656 - accuracy: 0.6392\n",
            "Epoch 63/150\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3590 - accuracy: 0.6350\n",
            "Epoch 64/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3510 - accuracy: 0.6336\n",
            "Epoch 65/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3362 - accuracy: 0.6392\n",
            "Epoch 66/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3123 - accuracy: 0.6392\n",
            "Epoch 67/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2816 - accuracy: 0.6434\n",
            "Epoch 68/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2495 - accuracy: 0.6490\n",
            "Epoch 69/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2213 - accuracy: 0.6573\n",
            "Epoch 70/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2000 - accuracy: 0.6615\n",
            "Epoch 71/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1847 - accuracy: 0.6587\n",
            "Epoch 72/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1728 - accuracy: 0.6587\n",
            "Epoch 73/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1614 - accuracy: 0.6573\n",
            "Epoch 74/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1483 - accuracy: 0.6559\n",
            "Epoch 75/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1331 - accuracy: 0.6531\n",
            "Epoch 76/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1165 - accuracy: 0.6545\n",
            "Epoch 77/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0999 - accuracy: 0.6629\n",
            "Epoch 78/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0850 - accuracy: 0.6727\n",
            "Epoch 79/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0730 - accuracy: 0.6741\n",
            "Epoch 80/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0637 - accuracy: 0.6741\n",
            "Epoch 81/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0557 - accuracy: 0.6755\n",
            "Epoch 82/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0471 - accuracy: 0.6727\n",
            "Epoch 83/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0366 - accuracy: 0.6727\n",
            "Epoch 84/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0245 - accuracy: 0.6769\n",
            "Epoch 85/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0121 - accuracy: 0.6741\n",
            "Epoch 86/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0008 - accuracy: 0.6769\n",
            "Epoch 87/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9912 - accuracy: 0.6769\n",
            "Epoch 88/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9831 - accuracy: 0.6769\n",
            "Epoch 89/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9756 - accuracy: 0.6769\n",
            "Epoch 90/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9678 - accuracy: 0.6769\n",
            "Epoch 91/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9592 - accuracy: 0.6783\n",
            "Epoch 92/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9503 - accuracy: 0.6783\n",
            "Epoch 93/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9418 - accuracy: 0.6783\n",
            "Epoch 94/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9343 - accuracy: 0.6769\n",
            "Epoch 95/150\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9277 - accuracy: 0.6755\n",
            "Epoch 96/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9217 - accuracy: 0.6769\n",
            "Epoch 97/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9156 - accuracy: 0.6769\n",
            "Epoch 98/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.9091 - accuracy: 0.6783\n",
            "Epoch 99/150\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9023 - accuracy: 0.6769\n",
            "Epoch 100/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8957 - accuracy: 0.6783\n",
            "Epoch 101/150\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8894 - accuracy: 0.6769\n",
            "Epoch 102/150\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8835 - accuracy: 0.6797\n",
            "Epoch 103/150\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8780 - accuracy: 0.6797\n",
            "Epoch 104/150\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8725 - accuracy: 0.6811\n",
            "Epoch 105/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.8669 - accuracy: 0.6825\n",
            "Epoch 106/150\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.8613 - accuracy: 0.6825\n",
            "Epoch 107/150\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8556 - accuracy: 0.6825\n",
            "Epoch 108/150\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8501 - accuracy: 0.6797\n",
            "Epoch 109/150\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.8450 - accuracy: 0.6783\n",
            "Epoch 110/150\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8401 - accuracy: 0.6783\n",
            "Epoch 111/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8352 - accuracy: 0.6783\n",
            "Epoch 112/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8302 - accuracy: 0.6769\n",
            "Epoch 113/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8251 - accuracy: 0.6825\n",
            "Epoch 114/150\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8200 - accuracy: 0.6867\n",
            "Epoch 115/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8151 - accuracy: 0.6867\n",
            "Epoch 116/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8105 - accuracy: 0.6895\n",
            "Epoch 117/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8058 - accuracy: 0.6909\n",
            "Epoch 118/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8012 - accuracy: 0.6909\n",
            "Epoch 119/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7967 - accuracy: 0.6881\n",
            "Epoch 120/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7922 - accuracy: 0.6881\n",
            "Epoch 121/150\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7878 - accuracy: 0.6867\n",
            "Epoch 122/150\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7835 - accuracy: 0.6895\n",
            "Epoch 123/150\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7794 - accuracy: 0.6909\n",
            "Epoch 124/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7753 - accuracy: 0.6951\n",
            "Epoch 125/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7711 - accuracy: 0.6951\n",
            "Epoch 126/150\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7669 - accuracy: 0.6965\n",
            "Epoch 127/150\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7628 - accuracy: 0.7049\n",
            "Epoch 128/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7588 - accuracy: 0.7063\n",
            "Epoch 129/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7548 - accuracy: 0.7063\n",
            "Epoch 130/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7509 - accuracy: 0.7063\n",
            "Epoch 131/150\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7470 - accuracy: 0.7035\n",
            "Epoch 132/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7431 - accuracy: 0.7063\n",
            "Epoch 133/150\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7393 - accuracy: 0.7077\n",
            "Epoch 134/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7355 - accuracy: 0.7091\n",
            "Epoch 135/150\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7318 - accuracy: 0.7077\n",
            "Epoch 136/150\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7281 - accuracy: 0.7077\n",
            "Epoch 137/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7244 - accuracy: 0.7077\n",
            "Epoch 138/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7208 - accuracy: 0.7133\n",
            "Epoch 139/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7171 - accuracy: 0.7133\n",
            "Epoch 140/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7135 - accuracy: 0.7133\n",
            "Epoch 141/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7099 - accuracy: 0.7175\n",
            "Epoch 142/150\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7063 - accuracy: 0.7189\n",
            "Epoch 143/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7029 - accuracy: 0.7175\n",
            "Epoch 144/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6995 - accuracy: 0.7189\n",
            "Epoch 145/150\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6962 - accuracy: 0.7217\n",
            "Epoch 146/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6929 - accuracy: 0.7203\n",
            "Epoch 147/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6896 - accuracy: 0.7217\n",
            "Epoch 148/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6864 - accuracy: 0.7245\n",
            "Epoch 149/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.7231\n",
            "Epoch 150/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6804 - accuracy: 0.7245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuD1YMYuFf9s",
        "outputId": "7fcf55c9-eb97-4903-87d2-736075ec93db"
      },
      "source": [
        "results = model.evaluate(np.array(test_data), np.array(test_labels),batch_size=715)\r\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6818 - accuracy: 0.7750\n",
            "test loss, test acc: [0.6817992329597473, 0.7749999761581421]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0WwZ0mBXJ40"
      },
      "source": [
        "We have a final accuracy around 75%. To obtain higher accuracy, we need more training data.\r\n"
      ]
    }
  ]
}